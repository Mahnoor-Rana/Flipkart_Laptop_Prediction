# -*- coding: utf-8 -*-
"""FlipKart-Laptop-Price-Prediction.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ucKGyv-GeyBG16VUTfw-FSJwv-cZBzRA

## Importing libraries
"""

from matplotlib import pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder, StandardScaler, MinMaxScaler
import numpy as np
import pandas as pd
import warnings
warnings.filterwarnings('ignore')

"""## Loading dataset"""

data = pd.read_csv('laptop_details.csv')

data.head(40)

"""#### Viewing one row in the dataset"""

row=data['Feature'][0]
row

laptop_df = data.copy()

df = [data.split('Processor')[0] for data in laptop_df['Feature']]
laptop_df['Feature'] = pd.DataFrame([data.split('Processor')[1] for data in laptop_df['Feature']])

laptop_df['Processor'] = pd.DataFrame(df)

data['Product'][0]

df = [data.split('RAM')[0] for data in laptop_df['Feature']]

laptop_df['RAM'] = pd.DataFrame(df)



laptop_df['Feature']

laptop_df.head()

"""### Using regex to extract meaningful data"""

import re

# regex pattern
pattern = '(?i)(AMD|Intel|Apple|Qualcomm)[a-z0-9 ]*Processor'

laptop_df['Processor'] = data.Feature.apply(lambda x: re.search(pattern,x).group() if(re.search(pattern,x)) else None)

laptop_df['Processor'].isnull().sum()

laptop_df.Processor.unique()

# Remove unnecessary words -> They don't convey much in this case (We could make a different feature for # of cores)
rem_processor = ['Processor', 'Dual Core', 'Quad Core', 'Hexa Core', 'Octa Core']
for string in rem_processor:
    laptop_df['Processor'] = laptop_df.Processor.str.replace(string,'')
laptop_df['Processor'] = laptop_df.Processor.str.strip()

laptop_df['Processor']

laptop_df.Processor.isnull().sum()

# Normally, we can drop these data points, but in this case it is manageable
laptop_df.Processor[laptop_df.Processor == 'Intel OptaneIntel Core i3']

laptop_df.Processor[6] = 'Intel Core i3'
laptop_df.Processor[172] = 'Intel Core i3'

laptop_df.Processor[laptop_df.Processor == 'Intel Evo Core i5']

laptop_df.Processor[53] = 'Intel Core i5'
laptop_df.Processor[116] = 'Intel Core i5'

laptop_df.Processor[laptop_df.Processor == 'Intel Pentium Silver']

laptop_df.Processor[94] = 'Intel Pentium'
laptop_df.Processor[235] = 'Intel Pentium'
laptop_df.Processor[389] = 'Intel Pentium'

laptop_df.Processor.unique()

# RAM
pattern = '[0-9]+ GB[ A-Z]*DDR[0-9]+[X]*|[0-9]+ GB Unified'
r = re.compile(pattern)
temp_ram=data.Feature.apply(lambda x: r.search(x).group(0) if(r.search(x)) else None)

laptop_df['RAM'] = pd.DataFrame(temp_ram)

temp_ram.isnull().sum()

# OS

pattern = 'Mac|DOS|Chrome|Windows'
r = re.compile(pattern)
temp_os=data.Feature.apply(lambda x: r.search(x).group(0) if(r.search(x)) else None)



laptop_df['OS'] = pd.DataFrame(temp_os)

laptop_df.OS

laptop_df.head()

# HDD
pattern = '[0-9]+ [A-Z ]*HDD[\/][0-9]+ [A-Z ]*SSD|[0-9]+ [A-Z ]*HDD|[0-9]+ [A-Z ]*SSD|[0-9]+ [A-Z ]*EMMC'
r = re.compile(pattern)
temp_hdd=data.Product.apply(lambda x: r.search(x).group(0) if(r.search(x)) else None)

pd.DataFrame(temp_hdd).to_csv('HDD_data.csv', ',')

laptop_df['HDD'] = pd.DataFrame(temp_hdd)

laptop_df.head()

laptop_df.head()

# Display
pattern = '[0-9.]+ inch|[0-9.]+ Inch'
r = re.compile(pattern)
temp_display=data.Feature.apply(lambda x: r.search(x).group(0) if(r.search(x)) else None)

"""temp_display"""

temp_display.isnull().sum()

laptop_df['Display'] = pd.DataFrame(temp_display)

laptop_df.Display=laptop_df.Display.str.replace('inch', '')
laptop_df.Display=laptop_df.Display.str.replace('Inch', '')
laptop_df.Display=laptop_df.Display.str.strip()

laptop_df

laptop_df

laptop_df.drop(columns=['Feature'], inplace=True)

laptop_df

# Cleaning RAM
laptop_df.RAM = pd.DataFrame([data.replace('GB','') for data in laptop_df.RAM])

laptop_df['RAM_size'] = pd.DataFrame([data.split()[0] for data in laptop_df.RAM])

laptop_df['RAM_type'] = pd.DataFrame([data.split()[-1] for data in laptop_df.RAM])

laptop_df.drop(columns='RAM', inplace=True)

laptop_df.RAM_type.value_counts()

laptop_df

# MRP

laptop_df['MRP']=laptop_df.MRP.str.replace(u'\u20B9','')
laptop_df['MRP']=laptop_df.MRP.str.replace(',','')

laptop_df



laptop_df.HDD

# HDD
laptop_df.HDD = laptop_df.HDD.str.replace('GB', '')
laptop_df.HDD

laptop_df.HDD = laptop_df.HDD.str.replace('TB', '')

laptop_df.HDD

pattern = "[0-9 ]+SSD|[0-9 ]+EMMC"
# r = re.compile(pattern)
temp_ssd=laptop_df.HDD.apply(lambda x: re.search(pattern,str(x)).group() if(re.search(pattern,str(x))) else None)

laptop_df['temp_ssd'] = pd.DataFrame(temp_ssd)

pattern = "[0-9 ]+HDD"
# r = re.compile(pattern)
temp_hdd=laptop_df.HDD.apply(lambda x: re.search(pattern,str(x)).group() if(re.search(pattern,str(x))) else None)

temp_hdd.isnull().sum()

laptop_df['temp_hdd'] = pd.DataFrame(temp_hdd)

temp_type = []
for data in laptop_df.HDD:
    if data:
        if ('HDD' in data) and ('SSD' in data):
            temp_type.append("Hybrid")
        elif ('HDD' in data) and ('SSD' not in data):
            temp_type.append("HDD")
        elif ('HDD' not in data) and ('SSD' in data):
            temp_type.append("SSD")
        else:
            temp_type.append("EMMC")
    else:
           temp_type.append(None)

laptop_df['HD_type'] = pd.DataFrame(temp_type)

laptop_df.temp_ssd

laptop_df.temp_ssd = laptop_df.temp_ssd.str.replace('SSD','')
laptop_df.temp_ssd = laptop_df.temp_ssd.str.replace('EMMC','')
laptop_df.temp_hdd = laptop_df.temp_hdd.str.replace('HDD','')
laptop_df.temp_ssd = laptop_df.temp_ssd.str.strip()
laptop_df.temp_hdd = laptop_df.temp_hdd.str.strip()

hdd_size = []
for data in laptop_df.temp_hdd:
    if data:
        if len(data)>1:
            hdd_size.append(data)
        else:
            hdd_size.append(str(1000 * int(data)))
    else:
        hdd_size.append(None)

pd.DataFrame(hdd_size).isnull().sum()

laptop_df.temp_hdd = pd.DataFrame(hdd_size)

laptop_df.temp_ssd

ssd_size = []
for data in laptop_df.temp_ssd:
    if data:
        if len(data)>1:
            ssd_size.append(data)
        else:
            ssd_size.append(str(1000 * int(data)))
    else:
        ssd_size.append(None)

laptop_df.temp_ssd = pd.DataFrame(ssd_size)



HD_size = []
for s1, s2 in zip(laptop_df.temp_ssd, laptop_df.temp_hdd):
    if s1 or s2:
        if s1 and s2:
            HD_size.append(int(s1)+int(s2))
        elif s1 and not s2:
            HD_size.append(int(s1))
        elif not s1 and s2:
            HD_size.append(int(s2))
    else:
        HD_size.append(None)

laptop_df['HD_size'] = pd.DataFrame(HD_size)

laptop_df.head()

# Now, drop temp_ssd and temp_hdd
laptop_df.drop(columns=['temp_ssd', 'temp_hdd'], inplace=True)

# Drop HDD column as well
laptop_df.drop(columns=['HDD'], inplace=True)

laptop_df.head()

laptop_df['Product'] = pd.DataFrame([data.split()[0] for data in laptop_df.Product])

laptop_df.Product=laptop_df.Product.str.strip()

laptop_df.head()

laptop_df.Product.unique()

# Rating
laptop_df.Rating.isnull().sum()

laptop_df.info()

convert_type = {
    'MRP': int,
    'Display':float,
    'RAM_size':int,
    'HD_size':int
}
laptop_df = laptop_df.astype(convert_type)

laptop_df.info()

laptop_df.RAM_type.isnull().sum()

#

# laptop_df.to_csv('LaptopDetailsClean.csv',',')

# Question
# Average rating based on product

laptop_df.groupby('Product')['Rating'].mean().plot(kind='barh')

# Average price based on the product type
ax = laptop_df.groupby('Product')['MRP'].mean().plot(kind='bar', figsize=(10,10))
for p in ax.patches:
    ax.annotate(u'\u20B9{:.0f}'.format(p.get_height()), (p.get_x(), p.get_height()+3), rotation=60)

laptop_df.info()

# Numerical Features
numerical_features = [feature for feature in laptop_df.columns if laptop_df[feature].dtypes!='O']
numerical_features

categorical_features = [feature for feature in laptop_df.columns if(laptop_df[feature].dtypes=='O')]
categorical_features

# Manually managing an outlier
laptop_df.Display[laptop_df.Display > 50]

# Replacing it with a correct value
laptop_df.Display[688] = 15.6

# Univariate Analysis of Numerical Features

# plt.figure(figsize=(15,15))
for i in range(0, len(numerical_features)):        
    laptop_df[numerical_features[i]].plot(kind='kde')
    plt.xlabel(numerical_features[i])
    plt.show()

"""### There is some skewness in all of the numerical features"""

# We can see some outliers, but we can't afford to lose any data. I'll use the log transformation to reduce the skewness later

# Let's check for the outliers
for i in range(0, len(numerical_features)):        
    laptop_df[numerical_features[i]].plot(kind='box')
    plt.show()

for feature in laptop_df.columns:
    laptop_df.plot(kind='scatter', x=feature, y= 'MRP', figsize=(10,10))
    plt.xticks(rotation=45)
    plt.show()

# RAM size and HD size has a positive relationship with the price of a laptop
# The processor type, HD type, RAM type do matter, but as the price is dependent on other specifications that's why we don't see a clear trend with price of a laptop
# brand is also a deciding factor, some brands focus on budget laptops, some target the specific group of community, others have a wide range of laptops
# no. of cores, GPU, Graphics etc. have not been considered in the dataset which also play a crucial role for deciding the price

# For further operations, let's copy the clean data into a new dataframe
laptop_df2 = laptop_df.copy()

laptop_df2.HD_type[laptop_df2.HD_type==0]

# Don't require to log transform discrete features
# #Log Transform Features
# for feature in ['HD_size', 'RAM_size', 'Display']:
#     laptop_df2[feature] = np.log(laptop_df2[feature])

laptop_df2['HD_size'].plot(kind='kde')

# Performing ordinal encoding on HD_type -> Laptops having Hybrid(HDD + SDD) are ranked highest.
HD_type_endict = {'HDD':1,
                  'EMMC':1.5,
                  'SSD':2,
                  'Hybrid':3}
laptop_df2['HD_type'] = laptop_df2.HD_type.map(HD_type_endict)

laptop_df.HD_type.isnull().sum()

laptop_df2.HD_type

laptop_df2.RAM_type.unique()

laptop_df2.RAM_type.isnull().sum()



# Ordinal encoding of RAM type
RAM_type_endict = {'LPDDR3':1,
                   'DDR4':2, 'LPDDR4':2, 'LPDDR4X':2,
                   'DDR5':3, 'LPDDR5':3,
                   'Unified':4
                  }
laptop_df2['RAM_type'] = laptop_df.RAM_type.map(RAM_type_endict)

laptop_df2.RAM_type

# Drop rating column
laptop_df2.drop(columns='Rating', inplace=True)

laptop_df2.info()

# Below graph does not show any relation with the type of RAM. Determining the price of a laptop is complex in itself, there are numerous features to consider.

laptop_df.plot(kind='scatter', x='RAM_type', y='MRP')

laptop_df.HD_type.unique()

laptop_df['MRP'].plot(kind='kde')

#Applying log transformation
laptop_df2['MRP']=np.log(laptop_df2.MRP)

## Log transformation has evidently normalized the MRP feature to some extent

laptop_df2['MRP'].plot(kind='kde')

y = laptop_df2['MRP']
laptop_df2.drop(columns=['MRP'], inplace=True)

laptop_df2.Processor.unique()

"""# Using below encoding techniques, I was able to increase the accuracy of both linear regression and SVR by about 8-9%

### The mapping is done based on the price not the performance. 
#### This may or may not comply with the mapping based on the performance
"""

# # laptop_df2.drop(columns=['Product'], inplace=True)
# processor_endict = {'Qualcomm':1,
#                     'AMD':2,
#                     'Intel':3,
#                     'Apple':4
# }
processor_endict = {'Qualcomm Snapdragon 7c Gen 2':1, 'Intel Pentium':1, 'Intel Celeron':1, 'AMD':1, 'AMD Athlon':1,
                   'Intel Core i3':2, 'AMD Ryzen 3':2,
                   'Intel Core i5':3, 'AMD Ryzen 5':3,
                   'Intel Core i7':4, 'AMD Ryzen 7':4,
                   'Intel Core i9':5, 'AMD Ryzen 9':5,
                   'Apple M1':6, 'Apple M1 Max':6, 'Apple M1 Pro':6,
                   'Apple M2':7}
laptop_df2['Processor'] = laptop_df2.Processor.map(processor_endict)

product_endict = {'Ultimus':1, 'Infinix':1,
                 'Lenovo':2, 'ASUS':2, 'realme':2,'acer':2,'RedmiBook':2, 'Vaio':2, 'Nokia':2,
                 'GIGABYTE':2,'MSI':2, 'HP':2, 'DELL':2, 'SAMSUNG':2,
                 'ALIENWARE':3, 'APPLE':3}
laptop_df2['Product'] = laptop_df2.Product.map(product_endict)

laptop_df2.Product.unique()

"""# Train Test Split"""

X_train, X_test, y_train, y_test = train_test_split(laptop_df2, y, test_size=0.2, random_state=36)

# Label encoding Categorical variables
# encode_product = LabelEncoder()
encode_os = LabelEncoder()
# encode_processor = LabelEncoder()

# X_train['Product'] = encode_product.fit_transform(X_train['Product'])
X_train['OS'] = encode_os.fit_transform(X_train['OS'])
# X_train['Processor'] = encode_processor.fit_transform(X_train['Processor'])

# X_test['Product'] = encode_product.transform(X_test['Product'])
X_test['OS'] = encode_os.transform(X_test['OS'])
# X_test['Processor'] = encode_processor.transform(X_test['Processor'])

X_test

# Scaling should be performed after splitting to avoid any data leakage

# scaler = StandardScaler()
scaler = MinMaxScaler(feature_range=(0,1))

X_train.columns

scaled_features = X_train.columns
X_train[scaled_features] = scaler.fit_transform(X_train[scaled_features].values)
X_test[scaled_features] = scaler.transform(X_test[scaled_features].values)

# 
y_scaler = StandardScaler()
# y_train = pd.DataFrame(y_train)
y_train = np.array(y_train).reshape(-1,1)
y_test = np.array(y_test).reshape(-1,1)
y_train = y_scaler.fit_transform(y_train)
y_test = y_scaler.transform(y_test)
y_train = pd.DataFrame(y_train)
y_test = pd.DataFrame(y_test)
y_train.columns=['MRP']
y_test.columns=['MRP']

# Correlation of features with target variable
for feature in X_train.columns:
    print(feature, X_train[feature].corr(y_train['MRP']))

"""# Training"""

from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
import seaborn as sns
import math
import pickle

reg = LinearRegression()

X_train = X_train.fillna(laptop_df.mean())
X_train.isnull().sum()

reg.fit(X_train, y_train)

y_pred = reg.predict(X_test)

"""# Result"""

mse = mean_squared_error(y_test, y_pred)
mae = mean_absolute_error(y_test, y_pred)
rmse = np.sqrt(mse)
print(f"mse: {mse}\nmae: {mae}\nrmse: {rmse}")

r2_score(y_test, y_pred)

# Predicting the price for a sample data

data = [['Lenovo','Intel Core i3','Windows',11.6,4,'LPDDR3','SSD',64]]
laptop_df_sample = pd.DataFrame(data, columns=['Product','Processor', 'OS', 'Display', 'RAM_size', 'RAM_type', 'HD_type', 'HD_size'])

laptop_df2.Product.unique()

laptop_df_sample.HD_size

# Performing necessary encodings

# laptop_df_sample

# laptop_df_sample['Product'] = encode_product.transform(laptop_df_sample['Product'])
laptop_df_sample['OS'] = encode_os.transform(laptop_df_sample['OS'])
# laptop_df_sample['Processor'] = encode_processor.transform(laptop_df_sample['Processor'])

laptop_df_sample['Processor'] = laptop_df_sample.Processor.map(processor_endict)

laptop_df_sample['Product'] = laptop_df_sample.Product.map(product_endict)

laptop_df_sample['RAM_type'] = laptop_df_sample.RAM_type.map(RAM_type_endict)

laptop_df_sample['HD_type'] = laptop_df_sample.HD_type.map(HD_type_endict)

# Don't need to log transform discrete data
# for feature in ['HD_size', 'RAM_size', 'Display']:
#     laptop_df_sample[feature] = np.log(laptop_df_sample[feature])

laptop_df_sample[scaled_features] = scaler.transform(laptop_df_sample[scaled_features].values)

laptop_df_sample

result=reg.predict(laptop_df_sample)

output=y_scaler.inverse_transform(result)

output

math.exp(output)

y_predd = y_pred.ravel()
y_predd.shape

# sns.regplot(y_test, y_predd)

from sklearn.svm import SVR

svr = SVR()

svr.fit(X_train, y_train)

yhat = svr.predict(X_test)

# sns.regplot(y_test, yhat)

r2_score(y_test,yhat)

res=svr.predict(laptop_df_sample)

res.reshape(-1,1)

res=y_scaler.inverse_transform(res.reshape(-1,1))

math.exp(res)

pickle.dump(svr,open('model.sav', 'wb'))

pickle.dump(scaler, open('scaler.sav', 'wb'))

pickle.dump(y_scaler, open('y_scaler.sav', 'wb'))

pickle.dump(encode_os, open('encode_os.sav', 'wb'))

pickle.dump(reg, open('finalized_model.sav', 'wb'))

model = pickle.load(open('finalized_model.sav', 'rb'))

out = model.predict(laptop_df_sample)

out = y_scaler.inverse_transform(out)

math.exp(out)

scal = pickle.load(open('scaler.sav', 'rb'))

scal.transform(laptop_df_sample[scaled_features].values)

